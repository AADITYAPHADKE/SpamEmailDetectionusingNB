# -*- coding: utf-8 -*-
"""spamdetection using NB--sucess

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aHHoHvjBpJ5U53AolXy5oSp5GHLOXsQs
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/spam.csv')
df.head()

df.groupby('Category').describe()

df['spam'] = df['Category'].apply(lambda x: 1 if x=='spam' else 0)
df.head() # spam = 1 and ham = 0

X_train,X_test,y_train,y_test = train_test_split(df.Message,df.spam,test_size = 0.25)

"""now to convert message column into numbers we use count vectorizer technique
so basically the countvectorizer assign every word a unique number and then differentiat it on bases of it

"""

from sklearn.feature_extraction.text import CountVectorizer

v = CountVectorizer()
X_train_count = v.fit_transform(X_train.values)
X_train_count.toarray()[:6]

X_test.head()

y_test.head()

X_test_count = v.fit_transform(X_test)
X_test_count.toarray()[:6]

X_test_count

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()

model.fit(X_train_count,y_train)

model.score(X_train_count,y_train)

emails =['Hey, are you free tonight','Get 200 off on 1000, this is deal is only for you, dont miss the reward']

"""#pipeline
-pipeline basically decreses the number of steps required to get a result i.e it might include data cleaning,data processing,hypertuning,training etc
-here in our case, our pipeline is going to include countvectorizer and data training and predictions

"""

from sklearn.pipeline import Pipeline

clf = Pipeline([('vectorizer',CountVectorizer()),('nb',MultinomialNB())])

"""as you can see now our pipeline does 2 tasks
this reduces time

"""

clf.fit(X_train,y_train)

clf.score(X_test,y_test)

clf.predict(emails)

